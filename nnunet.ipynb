{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn-UNet v2 Example\n",
    "Masoom Haider, MD, FRCPC, FSAR, FCAHS  \n",
    "Director AIMS Lab, Sinai Health System  \n",
    "Joint Dept of Medical Imaging, Univeristy of Toronto  \n",
    "\\\n",
    "\\\n",
    "GitHub Library for nnUNet  \n",
    "https://github.com/MIC-DKFZ/nnUNet  \n",
    "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring \n",
    "method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
    "\n",
    "This example uses some of the data from PI-CAI  \n",
    "https://pi-cai.grand-challenge.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "- Familiarity with Python coding - intermediate to expert level\n",
    "- Jupyter notebook installed in python environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation/Requirements\n",
    "- See https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/installation_instructions.md  \n",
    "- Will work on a single GPU workstation/gaming system i.e NVidia 4090 24G VRAM for abdo CT and MRI ($3-5K) 2025\n",
    "- GPU support for pytorch install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install nnUNetv2\n",
    "# %pip install nnunetv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_format.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DICOM to NIfTI\n",
    "- Many open source AI computer vision models don't directly support DICOM\n",
    "- Use the NIfTI format (Neuroimaging Informatics Technology Initiative)based requiring DICOM to NIfTI conversion\n",
    "- Watch out for series naming, mutiphase in one series, patched image volumes\n",
    "- Preparing and checking series can be time consuming and can benefit from AI tools for series extraction (research)\n",
    "- Watch out\n",
    "  - data compression schemes\n",
    "  - volume concantenation (multiphase, broken between chest , abdomen, pelvis)\n",
    "  - LAS-DICOM\n",
    "  - RAI (NIfTI)\n",
    "  - supine vs prone\n",
    "  - embedded localizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Libraries or Viewer Conversion - Not covered in this example**\n",
    "- **SimpleITK**\n",
    "- nibabel https://nipy.org/nibabel/\n",
    "- dicom2nifti https://github.com/icometrix/dicom2nifti\n",
    "- 3D Slicer https://www.slicer.org/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Data and Folder Structure\n",
    "Data and models are stored in a directory structure defined my some environment variables which must be setup before training and prediction  \n",
    "Same convention is used for training and prediction\n",
    "\n",
    "- MLDIRNAME\n",
    "  - nnUNet_raw\n",
    "      - Dataset001_BrainTumour *(this is the name of the model)*\n",
    "      - Dataset002_Heart\n",
    "      - Dataset003_Liver\n",
    "      - Dataset004_Hippocampus\n",
    "      - Dataset005_Prostate\n",
    "        - dataset.json\n",
    "        - imagesTr\n",
    "          - I_001_0000.nii.gz *(channel 0 = axt2)*\n",
    "          - I_001_0001.nii.gz *(channel 1 = adc)*\n",
    "          - I_001_0002.nii.gz *(channel 2 = b1600)*\n",
    "          - ...\n",
    "        - imagesTs\n",
    "        - labelsTr *(one label=segmentatotin masks regardless of number of channels)*\n",
    "          - I_001.nii.gz\n",
    "          - I_002.nii.gz\n",
    "          - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.nnunetutils import fInitialize\n",
    "\n",
    "mldatadir = os.path.join(os.environ('MLDATADIR'),'NNUNETTALKDATA')  # replace with your ML data path in this variable\n",
    "# You can put the PICAI directory in the repo in the mldatadir\n",
    "\n",
    "rootdir = os.path.join(mldatadir, 'NNUNET')\n",
    "modelname = 'Dataset100_prostate'\n",
    "dirdic = fInitialize(rootdir, modelname)  # creates directory structure and returns dictionary of dir locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nnunetutils import fPrepareFilesMP\n",
    "\n",
    "# where the PICAI data is located\n",
    "sourcedir = os.path.join(mldatadir, \"PICAI\")\n",
    "\n",
    "labels = {\n",
    "    'background': 0,\n",
    "    'tumor': 1\n",
    "}\n",
    "\n",
    "region_class_order = [1]\n",
    "imagefilenames = [\"axt2.nii.gz\", \"adc-axt2.nii.gz\",\"b1600-axt2.nii.gz\"]\n",
    "segfilename = \"t1_axt2_he.nii.gz\"\n",
    "channel_names = {0: \"axt2\", 1:\"adc\", 2:\"b1600\"}  \n",
    "\n",
    "fPrepareFilesMP(dirdic, channel_names, labels, sourcedir, imagefilenames, segfilename, region_class_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Images\n",
    "Determine imaging parameters to create an optimal UNet model architecture  \n",
    "\n",
    "https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/assets/nnU-Net_overview.png\n",
    "\n",
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nnunetutils import fPreProcess\n",
    "fPreProcess(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nnunetutils import fTrain\n",
    "configurations = ['3d_fullres'] #['2d', '3d_fullres', '3d_lowres', '3d_cascade_fullres']\n",
    "folds = [1]\n",
    "fTrain(modelname, configurations=configurations, folds=folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.nnunetutils import fPredict\n",
    "\n",
    "mldatadir = os.environ('MLDATADIR')  # put your ML data path in this variable\n",
    "rootdir = os.path.join(mldatadir, )\n",
    "modelname = 'Dataset100_prostate'\n",
    "\n",
    "# folder with case yuo wish to predict\n",
    "mFolder = os.path.join(mldatadir, r'PICAITEST\\AIPR_10005_20120718_1000005')  \n",
    "\n",
    "filestopredict  = [\"axt2.nii.gz\", \"adc-axt2.nii.gz\",\"b1600-axt2.nii.gz\"]\n",
    "sourcefnames = [os.path.join(mFolder, f) for f in filestopredict]\n",
    "segfilename = os.path.join(mFolder,\"t1_axt2_nnunet-100.nii.gz\")\n",
    "configuration = '3d_fullres'\n",
    "fPredict(rootdir, modelname, sourcefnames, segfilename, configuration)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
